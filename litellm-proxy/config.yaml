model_list:
  # Native Claude model names route to OpenAI backends ONLY
  # Claude Code will use these native names
  # Model Mapping Strategy:
  #   SMALL_MODEL:  claude-haiku  → gpt-4o-mini
  #   MIDDLE_MODEL: claude-sonnet → gpt-4o
  #   BIG_MODEL:    claude-opus   → o1

  # SMALL_MODEL: claude-haiku-4-5 -> OpenAI gpt-4o-mini (NO Anthropic passthrough)
  - model_name: claude-haiku-4-5
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096

  # MIDDLE_MODEL: claude-sonnet-4-5 -> OpenAI gpt-4o (NO Anthropic passthrough)
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 8192

  # BIG_MODEL: claude-opus-4-5 -> OpenAI o1 (NO Anthropic passthrough)
  - model_name: claude-opus-4-5
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 16384

# Router settings for easy switching
router_settings:
  model_group_alias:
    "claude-smart": "claude-opus-4-5"      # BIG_MODEL: Routes to o1
    "claude-fast": "claude-haiku-4-5"      # SMALL_MODEL: Routes to gpt-4o-mini
    "claude-code": "claude-sonnet-4-5"     # MIDDLE_MODEL: Routes to gpt-4o

# LiteLLM settings optimized for Claude 4 proxy
litellm_settings:
  forward_client_headers_to_llm_api: true
  drop_params: true  # Drop incompatible params during translation
  add_function_to_prompt: false
  set_verbose: true  # Enable verbose logging for debugging
  # Suppress tool translation for problematic tools
  disable_streaming_logging: false
  
general_settings:
  master_key: "sk-1234"
  store_model_in_db: False